{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "SEKW8_XvQ-wR"
      },
      "outputs": [],
      "source": [
        "# Este notebook contiene código para limpiar y procesar un dataset de seguros.\n",
        "# Se documentarán las diferentes secciones y funciones para una mejor comprensión.\n",
        "\n",
        "# Si no se está usando un ambiente virtual, descomentar y ejecutar las siguientes líneas\n",
        "# Instalar la librería numpy si no está instalada\n",
        "# !pip install numpy\n",
        "# Instalar la librería pandas si no está instalada\n",
        "# !pip install pandas\n",
        "# Instalar la librería ucimlrepo si no está instalada (parece no usarse en el código actual, pero se mantiene por si acaso)\n",
        "# !pip install ucimlrepo\n",
        "# Instalar la librería seaborn si no está instalada (parece no usarse en el código actual, pero se mantiene por si acaso)\n",
        "#!pip install seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfV89mklQ-wS",
        "outputId": "c6e951bf-65b5-4bcb-e569-1264873e55e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/bin/python3\n"
          ]
        }
      ],
      "source": [
        "# Importar el módulo sys para acceder a funcionalidades del sistema\n",
        "import sys\n",
        "# Imprimir la ruta del ejecutable de Python que se está utilizando\n",
        "print(sys.executable)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "5Har-2RcQ-wS"
      },
      "outputs": [],
      "source": [
        "# Cargando las librerías necesarias para el procesamiento de datos y visualización\n",
        "\n",
        "# Módulo para interactuar con el sistema operativo\n",
        "import os\n",
        "# Clase para trabajar con rutas de archivos de forma orientada a objetos\n",
        "from pathlib import Path\n",
        "# Módulo para operaciones con expresiones regulares\n",
        "import re\n",
        "# Librería para operaciones numéricas y arrays\n",
        "import numpy as np\n",
        "# Librería para manipulación y análisis de datos (DataFrames)\n",
        "import pandas as pd\n",
        "# Módulo para crear visualizaciones estáticas, interactivas y animadas en Python\n",
        "import matplotlib.pyplot as plt\n",
        "# Tipo de dato para columnas categóricas en pandas\n",
        "from pandas.api.types import CategoricalDtype\n",
        "# *Variable para controlar si se ignoran las advertencias\n",
        "ignore_warnings = True\n",
        "# *Librería para crear gráficos estadísticos atractivos\n",
        "import seaborn as sns\n",
        "# Módulo para trabajar con datos en formato JSON\n",
        "import json\n",
        "# *Función para obtener datasets del repositorio UCI\n",
        "#from ucimlrepo import fetch_ucirepo\n",
        "# *Módulo para trabajar con archivos YAML\n",
        "#import yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "nDslDGulQ-wT"
      },
      "outputs": [],
      "source": [
        "# --- Configuración mínima del script ---\n",
        "# Definir la ruta al archivo del diccionario de datos\n",
        "DICT_TXT = Path(r\"./data/raw/dictionary.txt\")\n",
        "# Definir la ruta al archivo CSV original modificado del dataset de la compañía de seguros\n",
        "CSV_PATH = Path(r\"./data/raw/insurance_company_modified.csv\")\n",
        "# Definir el directorio de salida para los datos limpios\n",
        "OUT_DIR  = Path(r\"./data/clean_data\")\n",
        "# Crear el directorio de salida si no existe (incluyendo directorios padres)\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "# Definir la ruta completa del archivo CSV limpio de salida\n",
        "OUT_CSV    = OUT_DIR / \"coil2000_clean.csv\"\n",
        "# Definir la ruta completa del archivo de reporte de tipos de datos de salida\n",
        "OUT_REPORT = OUT_DIR / \"coil2000_dtypes_report.csv\"\n",
        "# Definir el número esperado de columnas en el dataset\n",
        "N_COLS = 86\n",
        "# Definir un conjunto con los nombres de las columnas que deben ser tratadas como categóricas\n",
        "CAT_COLS = {\"MOSTYPE\", \"MOSHOOFD\", \"MKOOPKLA\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uo-8asqLQ-wT",
        "outputId": "34abc92b-41d3-4f8d-e9e9-62e8bffd5ec2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5938, 86)\n",
            "MOSTYPE ∈ [1, 41]: filas eliminadas = 75\n",
            "MAANTHUI ∈ [1, 10]: filas eliminadas = 67\n",
            "MGEMOMV ∈ [1, 6]: filas eliminadas = 62\n",
            "MGEMLEEF ∈ [1, 6]: filas eliminadas = 67\n",
            "MOSHOOFD ∈ [1, 10]: filas eliminadas = 56\n",
            "MGODRK ∈ [0, 9]: filas eliminadas = 26\n",
            "PWAPART ∈ [0, 9]: filas eliminadas = 42\n",
            "AWAPART ∈ [1, 12]: filas eliminadas = 2927\n",
            "CARAVAN ∈ [0, 1]: filas eliminadas = 8\n",
            "Filas eliminadas por nulos/vacíos: 1267\n",
            "Guardado dataset limpio: data/clean_data/coil2000_clean.csv\n",
            "Guardado reporte dtypes: data/clean_data/coil2000_dtypes_report.csv\n"
          ]
        }
      ],
      "source": [
        "# Definir los rangos válidos para algunas columnas numéricas para proceso de outliers\n",
        "RANGES = {\n",
        "    \"MOSTYPE\":  (1, 41),  # Rango para el tipo de cliente\n",
        "    \"MAANTHUI\": (1, 10),  # Rango para el número de casas\n",
        "    \"MGEMOMV\":  (1, 6),   # Rango para el ingreso promedio\n",
        "    \"MGEMLEEF\": (1, 6),   # Rango para la edad promedio\n",
        "    \"MOSHOOFD\": (1, 10),  # Rango para el tipo principal de cliente\n",
        "    \"MGODRK\":   (0, 9),   # Rango para la afiliación religiosa\n",
        "    \"PWAPART\":  (0, 9),   # Rango para el número de pólizas de seguro privado\n",
        "    \"AWAPART\":  (1, 12),  # Rango para el número de pólizas de seguro de coche\n",
        "    \"CARAVAN\":  (0, 1),   # Rango para si tiene caravana este es nuestra variable categórica (0: No, 1: Sí)\n",
        "}\n",
        "\n",
        "# Definir un patrón de expresión regular para identificar valores inválidos o nulos en strings\n",
        "INVALID_PATTERN = re.compile(r\"(?i)^\\s*$|^(nan|none|null|n/a|invalid|\\?|unknown|error|missing|-)$\")\n",
        "\n",
        "# 1) Función para parsear el diccionario de datos y obtener los nombres de las columnas\n",
        "def parse_dictionary(txt_path: Path):\n",
        "    # Leer el contenido del archivo de texto del diccionario\n",
        "    txt = txt_path.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
        "    # Lista para almacenar los nombres de las columnas\n",
        "    names = []\n",
        "    # Bandera para indicar si se está dentro de la sección de la tabla de columnas\n",
        "    in_table = False\n",
        "    # Iterar sobre cada línea del archivo\n",
        "    for ln in txt.splitlines():\n",
        "        # Eliminar espacios en blanco al inicio y final de la línea\n",
        "        ln = ln.strip()\n",
        "        # Verificar si la línea coincide con el inicio de la sección de la tabla\n",
        "        if re.match(r\"^1\\s+\\S+\", ln):\n",
        "            in_table = True\n",
        "        # Si no se está dentro de la tabla, saltar a la siguiente línea\n",
        "        if not in_table:\n",
        "            continue\n",
        "        # Verificar si la línea está vacía o empieza con \"L0\" (indicando el final de la tabla)\n",
        "        if not ln or ln.startswith(\"L0\"):\n",
        "            break\n",
        "        # Intentar extraer el número de columna y el nombre usando una expresión regular\n",
        "        m = re.match(r\"^(\\d+)\\s+(\\S+)\\s+.*$\", ln)\n",
        "        if m:\n",
        "            # Agregar el número de columna y el nombre a la lista\n",
        "            names.append((int(m.group(1)), m.group(2)))\n",
        "    # Ordenar los nombres de las columnas por su número y obtener solo los nombres\n",
        "    cols = [n for _, n in sorted(names, key=lambda x: x[0])]\n",
        "    # Verificar si el número de columnas obtenidas coincide con el número esperado\n",
        "    if len(cols) < N_COLS:\n",
        "        raise ValueError(f\"El diccionario tiene {len(cols)} nombres; se requieren {N_COLS}.\")\n",
        "    # Devolver solo el número de nombres de columnas\n",
        "    return cols[:N_COLS]\n",
        "\n",
        "# 2) Función para limpiar cadenas de caracters y reemplazarlos por NaN\n",
        "def normalize_strings_to_nan(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    # Crear una copia del DataFrame para no modificar el original\n",
        "    df = df.copy()\n",
        "    # Iterar sobre las columnas de tipo 'object'\n",
        "    for c in df.select_dtypes(include=\"object\").columns:\n",
        "        # Convertir la columna a tipo 'string' y eliminar espacios en blanco\n",
        "        df[c] = df[c].astype(\"string\").str.strip()\n",
        "    # Reemplazar los valores que coinciden con el patrón de inválidos por NaN\n",
        "    return df.replace(INVALID_PATTERN, np.nan, regex=True)\n",
        "\n",
        "# 3) Función para castear los tipos de datos de las columnas\n",
        "def cast_types(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    # Crear una copia del DataFrame\n",
        "    df = df.copy()\n",
        "    # Identificar las columnas que no son categóricas\n",
        "    non_cat = [c for c in df.columns if c not in CAT_COLS]\n",
        "    # Convertir las columnas no categóricas a tipo numérico, si hay errores NaN\n",
        "    df[non_cat] = df[non_cat].apply(pd.to_numeric, errors=\"coerce\")\n",
        "    # Convertir las columnas especificadas como categóricas a tipo 'category'\n",
        "    for c in CAT_COLS:\n",
        "        # Verificar si la columna existe en el DataFrame\n",
        "        if c in df.columns:\n",
        "            df[c] = df[c].astype(\"category\")\n",
        "    # Devuelve el DataFrame con los tipos de datos casteados\n",
        "    return df\n",
        "\n",
        "# 4) Función para aplicar reglas de validación por intervalos cerrados\n",
        "def apply_interval_rules(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    # Creamos una copia del DataFrame\n",
        "    df = df.copy()\n",
        "    # Imprimir la forma del DataFrame antes de aplicar las reglas\n",
        "    print(df.shape)\n",
        "\n",
        "    # Iterar sobre las columnas y sus rangos definidos\n",
        "    for col, (lo, hi) in RANGES.items():\n",
        "        # Verificar si la columna existe en el DataFrame\n",
        "        if col not in df.columns:\n",
        "            continue\n",
        "        # Convertir la columna a tipo numérico\n",
        "        s = pd.to_numeric(df[col].astype(\"string\").str.strip(), errors=\"coerce\") \\\n",
        "            if col in CAT_COLS or not pd.api.types.is_numeric_dtype(df[col]) else df[col]\n",
        "        # Crear una máscara booleana para identificar los valores dentro del rango\n",
        "        mask = s.between(lo, hi, inclusive=\"both\")\n",
        "        # Contar el número de filas que están fuera del rango\n",
        "        removed = (~mask).sum()\n",
        "        # Si se eliminaron filas, imprimir un mensaje\n",
        "        if removed:\n",
        "            print(f\"{col} ∈ [{lo}, {hi}]: filas eliminadas = {removed}\")\n",
        "        # Filtrar el DataFrame para mantener solo las filas dentro del rango y crear una nueva copia\n",
        "        df = df[mask].copy()\n",
        "    # Si la columna \"CARAVAN\" existe y sus valores son 0 o 1, convertirla a tipo entero\n",
        "    if \"CARAVAN\" in df.columns:\n",
        "        # Obtener los valores únicos no nulos de la columna\n",
        "        vals = set(pd.Series(df[\"CARAVAN\"]).dropna().unique().tolist())\n",
        "        # Verificar si los valores únicos están entre el rago {0, 1}\n",
        "        if vals <= {0, 1}:\n",
        "            # Convertir a numérico, luego a entero (permite NaN), y finalmente a entero nativo\n",
        "            df[\"CARAVAN\"] = pd.to_numeric(df[\"CARAVAN\"], errors=\"coerce\").astype(\"Int64\").astype(\"int64\")\n",
        "    # Restablecer el índice del DataFrame después de la eliminación de filas\n",
        "    df.reset_index(drop=True, inplace=True)\n",
        "    # Devolver el DataFrame con las reglas de intervalo aplicadas\n",
        "    return df\n",
        "\n",
        "# 5) Función para eliminar filas con valores nulos\n",
        "def enforce_no_nulls(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    # Reemplazar strings vacíos o que contienen solo espacios en blanco por NaN\n",
        "    df = df.replace(r\"^\\s*$\", np.nan, regex=True)\n",
        "    # Guardar el número de filas antes de eliminar nulos\n",
        "    before = len(df)\n",
        "    # Eliminar las filas que contienen al menos un valor nulo y restablecer el índice\n",
        "    df = df.dropna().reset_index(drop=True)\n",
        "    # Imprimir el número de filas eliminadas debido a nulos\n",
        "    print(f\"Filas eliminadas por nulos/vacíos: {before - len(df)}\")\n",
        "    # Devuelve el DataFrame sin filas con nulos\n",
        "    return df\n",
        "\n",
        "# 6) Pipeline principal de limpieza y procesamiento de datos\n",
        "def main():\n",
        "    # Hace parse al diccionario para obtener los nombres de las columnas\n",
        "    cols = parse_dictionary(DICT_TXT)\n",
        "\n",
        "    # Leer el archivo CSV en un DataFrame, sin encabezado\n",
        "    df = pd.read_csv(CSV_PATH, header=None)\n",
        "    # Verificar si el número de columnas del CSV coincide con el número esperado\n",
        "    if df.shape[1] < N_COLS:\n",
        "        raise ValueError(f\"El CSV tiene {df.shape[1]} columnas; se requieren {N_COLS}.\")\n",
        "    # Seleccionar solo el número esperado de columnas y crear una copia\n",
        "    df = df.iloc[:, :N_COLS].copy()\n",
        "    # Asignar los nombres de columnas obtenidos del diccionario\n",
        "    df.columns = cols\n",
        "\n",
        "    # Aplicar las funciones de limpieza en secuencia\n",
        "    # Normalizar strings y reemplazar por NaN\n",
        "    df = normalize_strings_to_nan(df)\n",
        "    # Aplicar reglas de intervalo\n",
        "    df = apply_interval_rules(df)\n",
        "    # Hacer la conversión de tipos de datos\n",
        "    df = cast_types(df)\n",
        "    # Eliminar filas con nulos\n",
        "    df = enforce_no_nulls(df)\n",
        "    # Verificar por valores nulos en el DataFrame resultante\n",
        "    assert df.isna().sum().sum() == 0\n",
        "\n",
        "    # Guardar el DataFrame limpio en un archivo CSV\n",
        "    df.to_csv(OUT_CSV, index=False)\n",
        "\n",
        "    # Crear un reporte con información sobre las columnas del DataFrame limpio\n",
        "    report = pd.DataFrame({\n",
        "        # Nombres de las columnas\n",
        "        \"columna\": df.columns,\n",
        "        # Tipos de datos finales como strings\n",
        "        \"dtype_final\": df.dtypes.astype(str).values,\n",
        "        # Número de valores nulos por columna\n",
        "        \"nulos\": df.isna().sum().values,\n",
        "        # Número de valores únicos no nulos por columna\n",
        "        \"unicos\": df.nunique(dropna=True).values,\n",
        "        # Indica si la columna fue tratada como categórica\n",
        "        \"es_categorica\": [c in CAT_COLS for c in df.columns],\n",
        "    })\n",
        "    # Guardar el reporte de tipos de datos en un archivo CSV\n",
        "    report.to_csv(OUT_REPORT, index=False)\n",
        "\n",
        "    # Imprimir mensajes de confirmación\n",
        "    print(f\"Guardado dataset limpio: {OUT_CSV}\")\n",
        "    print(f\"Guardado reporte dtypes: {OUT_REPORT}\")\n",
        "\n",
        "# Ejecutar la función principal si el script se ejecuta directamente\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "devstack",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}