{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SEKW8_XvQ-wR"
      },
      "outputs": [],
      "source": [
        "# Este notebook contiene código para limpiar y procesar un dataset de seguros.\n",
        "# Se documentarán las diferentes secciones y funciones para una mejor comprensión.\n",
        "\n",
        "# Si no se está usando un ambiente virtual, descomentar y ejecutar las siguientes líneas\n",
        "# Instalar la librería numpy si no está instalada\n",
        "# !pip install numpy\n",
        "# Instalar la librería pandas si no está instalada\n",
        "# !pip install pandas\n",
        "# Instalar la librería ucimlrepo si no está instalada (parece no usarse en el código actual, pero se mantiene por si acaso)\n",
        "# !pip install ucimlrepo\n",
        "# Instalar la librería seaborn si no está instalada (parece no usarse en el código actual, pero se mantiene por si acaso)\n",
        "#!pip install seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfV89mklQ-wS",
        "outputId": "c6e951bf-65b5-4bcb-e569-1264873e55e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "c:\\Users\\chile\\anaconda3\\envs\\devstack\\python.exe\n"
          ]
        }
      ],
      "source": [
        "# Importar el módulo sys para acceder a funcionalidades del sistema\n",
        "import sys\n",
        "# Imprimir la ruta del ejecutable de Python que se está utilizando\n",
        "print(sys.executable)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "5Har-2RcQ-wS"
      },
      "outputs": [],
      "source": [
        "# Cargando las librerías necesarias para el procesamiento de datos y visualización\n",
        "\n",
        "# Módulo para interactuar con el sistema operativo\n",
        "import os\n",
        "# Módulo para operaciones con expresiones regulares\n",
        "import re\n",
        "# Librería para operaciones numéricas y arrays\n",
        "import numpy as np\n",
        "# Librería para manipulación y análisis de datos (DataFrames)\n",
        "import pandas as pd\n",
        "# Módulo para crear visualizaciones estáticas, interactivas y animadas en Python\n",
        "import matplotlib.pyplot as plt\n",
        "# Tipo de dato para columnas categóricas en pandas\n",
        "from pandas.api.types import CategoricalDtype\n",
        "# *Variable para controlar si se ignoran las advertencias\n",
        "ignore_warnings = True\n",
        "# *Librería para crear gráficos estadísticos atractivos\n",
        "import seaborn as sns\n",
        "# Módulo para trabajar con datos en formato JSON\n",
        "import json\n",
        "# *Función para obtener datasets del repositorio UCI\n",
        "#from ucimlrepo import fetch_ucirepo\n",
        "# *Módulo para trabajar con archivos YAML\n",
        "import yaml\n",
        "# Clase para trabajar con rutas de archivos de forma orientada a objetos\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Intentando abrir: C:\\Users\\chile\\projects\\Mlops_proyect-main\\config\\params.yaml\n",
            "\n",
            "--- CONTENIDO DEL YAML LEÍDO ---\n",
            "\n",
            "--------------------------------\n",
            "\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'NoneType' object has no attribute 'get'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[41]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     11\u001b[39m cfg = yaml.safe_load(text)\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m#print(\"Claves de nivel 1:\", list(cfg.keys()))\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mClaves en paths:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mlist\u001b[39m(\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m(\u001b[33m\"\u001b[39m\u001b[33mpaths\u001b[39m\u001b[33m\"\u001b[39m, {}).keys()))\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Validaciones amistosas\u001b[39;00m\n\u001b[32m     16\u001b[39m required = {\u001b[33m\"\u001b[39m\u001b[33mdata_dir\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mraw_dir\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mclean_dir\u001b[39m\u001b[33m\"\u001b[39m}\n",
            "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'get'"
          ]
        }
      ],
      "source": [
        "# Ruta que estás usando para abrir el YAML\n",
        "yaml_path = (Path.cwd().parent / \"config\" / \"params.yaml\").resolve()\n",
        "print(\"Intentando abrir:\", yaml_path)\n",
        "\n",
        "# Muestra el contenido real del archivo que se está leyendo\n",
        "text = yaml_path.read_text(encoding=\"utf-8\")\n",
        "print(\"\\n--- CONTENIDO DEL YAML LEÍDO ---\")\n",
        "print(text)\n",
        "print(\"--------------------------------\\n\")\n",
        "\n",
        "cfg = yaml.safe_load(text)\n",
        "#print(\"Claves de nivel 1:\", list(cfg.keys()))\n",
        "print(\"Claves en paths:\", list(cfg.get(\"paths\", {}).keys()))\n",
        "\n",
        "# Validaciones amistosas\n",
        "required = {\"data_dir\", \"raw_dir\", \"clean_dir\"}\n",
        "missing = required - set(cfg.get(\"paths\", {}).keys())\n",
        "assert not missing, f\"Faltan claves en paths: {missing}\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Escribí: C:\\Users\\chile\\projects\\Mlops_proyect-main\\config\\params.yaml\n",
            "Tamaño (bytes): 317\n",
            "Contenido guardado:\n",
            "\n",
            "paths:\n",
            "  raw: data/enriched/insurance_company_enriched.csv\n",
            "  interim: data/interim/data_clean.parquet\n",
            "  processed: data/processed/data_model.parquet\n",
            "  report_html: reports/eda_clean.html\n",
            "  report_css: reports/assets/css/report.css\n",
            "  root: .\n",
            "  data_dir: data\n",
            "  raw_dir: data/raw\n",
            "  clean_dir: data/clean_data\n",
            "\n"
          ]
        }
      ],
      "source": [
        "yaml_text = \"\"\"paths:\n",
        "  raw: data/enriched/insurance_company_enriched.csv\n",
        "  interim: data/interim/data_clean.parquet\n",
        "  processed: data/processed/data_model.parquet\n",
        "  report_html: reports/eda_clean.html\n",
        "  report_css: reports/assets/css/report.css\n",
        "  root: .\n",
        "  data_dir: data\n",
        "  raw_dir: data/raw\n",
        "  clean_dir: data/clean_data\n",
        "\"\"\"\n",
        "\n",
        "yaml_path = (Path.cwd().parent / \"config\" / \"params.yaml\").resolve()\n",
        "yaml_path.write_text(yaml_text, encoding=\"utf-8\")\n",
        "\n",
        "print(\"Escribí:\", yaml_path)\n",
        "print(\"Tamaño (bytes):\", yaml_path.stat().st_size)\n",
        "print(\"Contenido guardado:\\n\")\n",
        "print(yaml_path.read_text(encoding=\"utf-8\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Leyendo: C:\\Users\\chile\\projects\\Mlops_proyect-main\\config\\params.yaml\n",
            "Claves de nivel 1: ['paths']\n",
            "Claves dentro de 'paths': ['raw', 'interim', 'processed', 'report_html', 'report_css', 'root', 'data_dir', 'raw_dir', 'clean_dir']\n"
          ]
        }
      ],
      "source": [
        "yaml_path = (Path.cwd().parent / \"config\" / \"params.yaml\").resolve()\n",
        "print(\"Leyendo:\", yaml_path)\n",
        "\n",
        "with open(yaml_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    cfg = yaml.safe_load(f)\n",
        "\n",
        "print(\"Claves de nivel 1:\", list(cfg.keys()))\n",
        "print(\"Claves dentro de 'paths':\", list(cfg[\"paths\"].keys()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mostrar exactamente qué archivo se está abriendo\n",
        "yaml_path = (Path.cwd().parent / \"config\" / \"params.yaml\").resolve()\n",
        "print(\"Archivo YAML que se está abriendo:\")\n",
        "print(yaml_path)\n",
        "print(\"\\n¿Existe realmente ese archivo?:\", yaml_path.exists())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Detectar raíz del proyecto (subiendo desde notebooks/)\n",
        "PROJECT_ROOT = Path.cwd().parent\n",
        "\n",
        "# Extraer rutas\n",
        "DATA_DIR  = PROJECT_ROOT / cfg[\"paths\"][\"data_dir\"]\n",
        "RAW_DIR   = PROJECT_ROOT / cfg[\"paths\"][\"raw_dir\"]\n",
        "CLEAN_DIR = PROJECT_ROOT / cfg[\"paths\"][\"clean_dir\"]\n",
        "\n",
        "# Archivos\n",
        "DICT_TXT   = PROJECT_ROOT / cfg[\"files\"][\"dictionary\"]\n",
        "CSV_PATH   = PROJECT_ROOT / cfg[\"files\"][\"csv_input\"]\n",
        "OUT_CSV    = PROJECT_ROOT / cfg[\"files\"][\"csv_output\"]\n",
        "OUT_REPORT = PROJECT_ROOT / cfg[\"files\"][\"report_output\"]\n",
        "\n",
        "# Crear carpeta de salida si no existe\n",
        "CLEAN_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
        "print(\"CSV_PATH existe:\", CSV_PATH.exists())\n",
        "print(\"Salida limpia:\", OUT_CSV)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Detectar la raíz del proyecto (un nivel arriba del notebook)\n",
        "PROJECT_ROOT = Path.cwd().parent if Path.cwd().name == \"notebooks\" else Path.cwd()\n",
        "\n",
        "# Rutas basadas en la raíz real del proyecto\n",
        "DATA_DIR = PROJECT_ROOT / \"data\"\n",
        "RAW_DIR  = DATA_DIR / \"raw\"\n",
        "CLEAN_DIR = DATA_DIR / \"clean_data\"\n",
        "\n",
        "# Archivos de entrada y salida\n",
        "DICT_TXT   = RAW_DIR / \"dictionary.txt\"\n",
        "CSV_PATH   = RAW_DIR / \"insurance_company_modified.csv\"\n",
        "OUT_DIR    = CLEAN_DIR\n",
        "OUT_CSV    = OUT_DIR / \"coil2000_clean.csv\"\n",
        "OUT_REPORT = OUT_DIR / \"coil2000_dtypes_report.csv\"\n",
        "\n",
        "# Crear el directorio de salida si no existe\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Mostrar verificación\n",
        "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
        "print(\"DICT_TXT exists:\", DICT_TXT.exists())\n",
        "print(\"CSV_PATH exists:\", CSV_PATH.exists())\n",
        "print(\"OUT_DIR:\", OUT_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Definir el número esperado de columnas en el dataset\n",
        "N_COLS = 86\n",
        "# Definir un conjunto con los nombres de las columnas que deben ser tratadas como categóricas\n",
        "CAT_COLS = {\"MOSTYPE\", \"MOSHOOFD\", \"MKOOPKLA\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nDslDGulQ-wT"
      },
      "outputs": [],
      "source": [
        "# --- Configuración mínima del script ---\n",
        "# Definir la ruta al archivo del diccionario de datos\n",
        "#DICT_TXT = Path(r\"./data/raw/dictionary.txt\")\n",
        "# Definir la ruta al archivo CSV original modificado del dataset de la compañía de seguros\n",
        "#CSV_PATH = Path(r\"./data/raw/insurance_company_modified.csv\")\n",
        "# Definir el directorio de salida para los datos limpios\n",
        "#OUT_DIR  = Path(r\"./data/clean_data\")\n",
        "# Crear el directorio de salida si no existe (incluyendo directorios padres)\n",
        "#OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "# Definir la ruta completa del archivo CSV limpio de salida\n",
        "#OUT_CSV    = OUT_DIR / \"coil2000_clean.csv\"\n",
        "# Definir la ruta completa del archivo de reporte de tipos de datos de salida\n",
        "#OUT_REPORT = OUT_DIR / \"coil2000_dtypes_report.csv\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uo-8asqLQ-wT",
        "outputId": "34abc92b-41d3-4f8d-e9e9-62e8bffd5ec2"
      },
      "outputs": [],
      "source": [
        "# Definir los rangos válidos para algunas columnas numéricas para proceso de outliers\n",
        "RANGES = {\n",
        "    \"MOSTYPE\":  (1, 41),  # Rango para el tipo de cliente\n",
        "    \"MAANTHUI\": (1, 10),  # Rango para el número de casas\n",
        "    \"MGEMOMV\":  (1, 6),   # Rango para el ingreso promedio\n",
        "    \"MGEMLEEF\": (1, 6),   # Rango para la edad promedio\n",
        "    \"MOSHOOFD\": (1, 10),  # Rango para el tipo principal de cliente\n",
        "    \"MGODRK\":   (0, 9),   # Rango para la afiliación religiosa\n",
        "    \"PWAPART\":  (0, 9),   # Rango para el número de pólizas de seguro privado\n",
        "    \"AWAPART\":  (1, 12),  # Rango para el número de pólizas de seguro de coche\n",
        "    \"CARAVAN\":  (0, 1),   # Rango para si tiene caravana este es nuestra variable categórica (0: No, 1: Sí)\n",
        "}\n",
        "\n",
        "# Definir un patrón de expresión regular para identificar valores inválidos o nulos en strings\n",
        "INVALID_PATTERN = re.compile(r\"(?i)^\\s*$|^(nan|none|null|n/a|invalid|\\?|unknown|error|missing|-)$\")\n",
        "\n",
        "# 1) Función para parsear el diccionario de datos y obtener los nombres de las columnas\n",
        "def parse_dictionary(txt_path: Path):\n",
        "    # Leer el contenido del archivo de texto del diccionario\n",
        "    txt = txt_path.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
        "    # Lista para almacenar los nombres de las columnas\n",
        "    names = []\n",
        "    # Bandera para indicar si se está dentro de la sección de la tabla de columnas\n",
        "    in_table = False\n",
        "    # Iterar sobre cada línea del archivo\n",
        "    for ln in txt.splitlines():\n",
        "        # Eliminar espacios en blanco al inicio y final de la línea\n",
        "        ln = ln.strip()\n",
        "        # Verificar si la línea coincide con el inicio de la sección de la tabla\n",
        "        if re.match(r\"^1\\s+\\S+\", ln):\n",
        "            in_table = True\n",
        "        # Si no se está dentro de la tabla, saltar a la siguiente línea\n",
        "        if not in_table:\n",
        "            continue\n",
        "        # Verificar si la línea está vacía o empieza con \"L0\" (indicando el final de la tabla)\n",
        "        if not ln or ln.startswith(\"L0\"):\n",
        "            break\n",
        "        # Intentar extraer el número de columna y el nombre usando una expresión regular\n",
        "        m = re.match(r\"^(\\d+)\\s+(\\S+)\\s+.*$\", ln)\n",
        "        if m:\n",
        "            # Agregar el número de columna y el nombre a la lista\n",
        "            names.append((int(m.group(1)), m.group(2)))\n",
        "    # Ordenar los nombres de las columnas por su número y obtener solo los nombres\n",
        "    cols = [n for _, n in sorted(names, key=lambda x: x[0])]\n",
        "    # Verificar si el número de columnas obtenidas coincide con el número esperado\n",
        "    if len(cols) < N_COLS:\n",
        "        raise ValueError(f\"El diccionario tiene {len(cols)} nombres; se requieren {N_COLS}.\")\n",
        "    # Devolver solo el número de nombres de columnas\n",
        "    return cols[:N_COLS]\n",
        "\n",
        "# 2) Función para limpiar cadenas de caracters y reemplazarlos por NaN\n",
        "def normalize_strings_to_nan(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    # Crear una copia del DataFrame para no modificar el original\n",
        "    df = df.copy()\n",
        "    # Iterar sobre las columnas de tipo 'object'\n",
        "    for c in df.select_dtypes(include=\"object\").columns:\n",
        "        # Convertir la columna a tipo 'string' y eliminar espacios en blanco\n",
        "        df[c] = df[c].astype(\"string\").str.strip()\n",
        "    # Reemplazar los valores que coinciden con el patrón de inválidos por NaN\n",
        "    return df.replace(INVALID_PATTERN, np.nan, regex=True)\n",
        "\n",
        "# 3) Función para castear los tipos de datos de las columnas\n",
        "def cast_types(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    # Crear una copia del DataFrame\n",
        "    df = df.copy()\n",
        "    # Identificar las columnas que no son categóricas\n",
        "    non_cat = [c for c in df.columns if c not in CAT_COLS]\n",
        "    # Convertir las columnas no categóricas a tipo numérico, si hay errores NaN\n",
        "    df[non_cat] = df[non_cat].apply(pd.to_numeric, errors=\"coerce\")\n",
        "    # Convertir las columnas especificadas como categóricas a tipo 'category'\n",
        "    for c in CAT_COLS:\n",
        "        # Verificar si la columna existe en el DataFrame\n",
        "        if c in df.columns:\n",
        "            df[c] = df[c].astype(\"category\")\n",
        "    # Devuelve el DataFrame con los tipos de datos casteados\n",
        "    return df\n",
        "\n",
        "# 4) Función para aplicar reglas de validación por intervalos cerrados\n",
        "def apply_interval_rules(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    # Creamos una copia del DataFrame\n",
        "    df = df.copy()\n",
        "    # Imprimir la forma del DataFrame antes de aplicar las reglas\n",
        "    print(df.shape)\n",
        "\n",
        "    # Iterar sobre las columnas y sus rangos definidos\n",
        "    for col, (lo, hi) in RANGES.items():\n",
        "        # Verificar si la columna existe en el DataFrame\n",
        "        if col not in df.columns:\n",
        "            continue\n",
        "        # Convertir la columna a tipo numérico\n",
        "        s = pd.to_numeric(df[col].astype(\"string\").str.strip(), errors=\"coerce\") \\\n",
        "            if col in CAT_COLS or not pd.api.types.is_numeric_dtype(df[col]) else df[col]\n",
        "        # Crear una máscara booleana para identificar los valores dentro del rango\n",
        "        mask = s.between(lo, hi, inclusive=\"both\")\n",
        "        # Contar el número de filas que están fuera del rango\n",
        "        removed = (~mask).sum()\n",
        "        # Si se eliminaron filas, imprimir un mensaje\n",
        "        if removed:\n",
        "            print(f\"{col} ∈ [{lo}, {hi}]: filas eliminadas = {removed}\")\n",
        "        # Filtrar el DataFrame para mantener solo las filas dentro del rango y crear una nueva copia\n",
        "        df = df[mask].copy()\n",
        "    # Si la columna \"CARAVAN\" existe y sus valores son 0 o 1, convertirla a tipo entero\n",
        "    if \"CARAVAN\" in df.columns:\n",
        "        # Obtener los valores únicos no nulos de la columna\n",
        "        vals = set(pd.Series(df[\"CARAVAN\"]).dropna().unique().tolist())\n",
        "        # Verificar si los valores únicos están entre el rago {0, 1}\n",
        "        if vals <= {0, 1}:\n",
        "            # Convertir a numérico, luego a entero (permite NaN), y finalmente a entero nativo\n",
        "            df[\"CARAVAN\"] = pd.to_numeric(df[\"CARAVAN\"], errors=\"coerce\").astype(\"Int64\").astype(\"int64\")\n",
        "    # Restablecer el índice del DataFrame después de la eliminación de filas\n",
        "    df.reset_index(drop=True, inplace=True)\n",
        "    # Devolver el DataFrame con las reglas de intervalo aplicadas\n",
        "    return df\n",
        "\n",
        "# 5) Función para eliminar filas con valores nulos\n",
        "def enforce_no_nulls(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    # Reemplazar strings vacíos o que contienen solo espacios en blanco por NaN\n",
        "    df = df.replace(r\"^\\s*$\", np.nan, regex=True)\n",
        "    # Guardar el número de filas antes de eliminar nulos\n",
        "    before = len(df)\n",
        "    # Eliminar las filas que contienen al menos un valor nulo y restablecer el índice\n",
        "    df = df.dropna().reset_index(drop=True)\n",
        "    # Imprimir el número de filas eliminadas debido a nulos\n",
        "    print(f\"Filas eliminadas por nulos/vacíos: {before - len(df)}\")\n",
        "    # Devuelve el DataFrame sin filas con nulos\n",
        "    return df\n",
        "\n",
        "# 6) Pipeline principal de limpieza y procesamiento de datos\n",
        "def main():\n",
        "    # Hace parse al diccionario para obtener los nombres de las columnas\n",
        "    cols = parse_dictionary(DICT_TXT)\n",
        "\n",
        "    # Leer el archivo CSV en un DataFrame, sin encabezado\n",
        "    df = pd.read_csv(CSV_PATH, header=None)\n",
        "    # Verificar si el número de columnas del CSV coincide con el número esperado\n",
        "    if df.shape[1] < N_COLS:\n",
        "        raise ValueError(f\"El CSV tiene {df.shape[1]} columnas; se requieren {N_COLS}.\")\n",
        "    # Seleccionar solo el número esperado de columnas y crear una copia\n",
        "    df = df.iloc[:, :N_COLS].copy()\n",
        "    # Asignar los nombres de columnas obtenidos del diccionario\n",
        "    df.columns = cols\n",
        "\n",
        "    # Aplicar las funciones de limpieza en secuencia\n",
        "    # Normalizar strings y reemplazar por NaN\n",
        "    df = normalize_strings_to_nan(df)\n",
        "    # Aplicar reglas de intervalo\n",
        "    df = apply_interval_rules(df)\n",
        "    # Hacer la conversión de tipos de datos\n",
        "    df = cast_types(df)\n",
        "    # Eliminar filas con nulos\n",
        "    df = enforce_no_nulls(df)\n",
        "    # Verificar por valores nulos en el DataFrame resultante\n",
        "    assert df.isna().sum().sum() == 0\n",
        "\n",
        "    # Guardar el DataFrame limpio en un archivo CSV\n",
        "    df.to_csv(OUT_CSV, index=False)\n",
        "\n",
        "    # Crear un reporte con información sobre las columnas del DataFrame limpio\n",
        "    report = pd.DataFrame({\n",
        "        # Nombres de las columnas\n",
        "        \"columna\": df.columns,\n",
        "        # Tipos de datos finales como strings\n",
        "        \"dtype_final\": df.dtypes.astype(str).values,\n",
        "        # Número de valores nulos por columna\n",
        "        \"nulos\": df.isna().sum().values,\n",
        "        # Número de valores únicos no nulos por columna\n",
        "        \"unicos\": df.nunique(dropna=True).values,\n",
        "        # Indica si la columna fue tratada como categórica\n",
        "        \"es_categorica\": [c in CAT_COLS for c in df.columns],\n",
        "    })\n",
        "    # Guardar el reporte de tipos de datos en un archivo CSV\n",
        "    report.to_csv(OUT_REPORT, index=False)\n",
        "\n",
        "    # Imprimir mensajes de confirmación\n",
        "    print(f\"Guardado dataset limpio: {OUT_CSV}\")\n",
        "    print(f\"Guardado reporte dtypes: {OUT_REPORT}\")\n",
        "\n",
        "# Ejecutar la función principal si el script se ejecuta directamente\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "devstack",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
