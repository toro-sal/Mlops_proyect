{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "5b65a3eb",
      "metadata": {},
      "source": [
        "# 03 · Baseline Modeling\n",
        "Entrenamos un primer modelo supervisado usando el dataset limpio generado en el cuaderno de preprocesamiento; si no existe, lo recreamos aquí con funciones locales.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "a975a7ab",
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import re\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import yaml\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "9169fd42",
      "metadata": {},
      "outputs": [],
      "source": [
        "MISSING_TOKENS = {\n",
        "    '', ' ', 'na', 'n/a', 'nan', 'none', 'null', '?', 'unknown', 'missing', 'invalid', 'bad', '--'\n",
        "}\n",
        "\n",
        "def load_raw_dataframe(path: Path) -> pd.DataFrame:\n",
        "    return pd.read_csv(path, low_memory=False, keep_default_na=False)\n",
        "\n",
        "\n",
        "def slugify(name: str) -> str:\n",
        "    name = re.sub(r\"[^\\w]+\", '_', name.strip().lower())\n",
        "    name = re.sub(r\"_+\", '_', name).strip('_')\n",
        "    if not name:\n",
        "        name = 'col'\n",
        "    if name[0].isdigit():\n",
        "        name = f'col_{name}'\n",
        "    return name\n",
        "\n",
        "\n",
        "def normalize_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    df = df.copy()\n",
        "    seen = {}\n",
        "    new_cols = []\n",
        "    for col in df.columns:\n",
        "        base = slugify(str(col))\n",
        "        count = seen.get(base, 0)\n",
        "        if count:\n",
        "            new_cols.append(f\"{base}_{count}\")\n",
        "        else:\n",
        "            new_cols.append(base)\n",
        "        seen[base] = count + 1\n",
        "    df.columns = new_cols\n",
        "    return df\n",
        "\n",
        "\n",
        "def standardize_missing(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    df = df.copy()\n",
        "    tokens = {t.lower() for t in MISSING_TOKENS}\n",
        "    for col in df.columns:\n",
        "        if pd.api.types.is_object_dtype(df[col]):\n",
        "            series = df[col].astype(str)\n",
        "            mask = series.str.strip().str.lower().isin(tokens)\n",
        "            df[col] = series.where(~mask).replace({'': np.nan})\n",
        "    return df\n",
        "\n",
        "\n",
        "def coerce_numeric(df: pd.DataFrame, numeric_like_ratio: float = 0.8):\n",
        "    df = df.copy()\n",
        "    numeric_cols = []\n",
        "    for col in df.columns:\n",
        "        if pd.api.types.is_numeric_dtype(df[col]):\n",
        "            numeric_cols.append(col)\n",
        "            continue\n",
        "        if not pd.api.types.is_object_dtype(df[col]):\n",
        "            continue\n",
        "        coerced = pd.to_numeric(df[col], errors='coerce')\n",
        "        non_na = coerced.notna().sum()\n",
        "        if non_na == 0:\n",
        "            continue\n",
        "        ratio = non_na / len(df)\n",
        "        if ratio >= numeric_like_ratio:\n",
        "            df[col] = coerced\n",
        "            numeric_cols.append(col)\n",
        "    return df, numeric_cols\n",
        "\n",
        "\n",
        "def mask_outliers(df: pd.DataFrame, threshold: float = 4.0):\n",
        "    df = df.copy()\n",
        "    masked_cols = []\n",
        "    for col in df.select_dtypes(include=[np.number]).columns:\n",
        "        series = df[col]\n",
        "        std = series.std(skipna=True)\n",
        "        mean = series.mean(skipna=True)\n",
        "        if std and std > 0:\n",
        "            z = (series - mean) / std\n",
        "            mask = z.abs() > threshold\n",
        "            if mask.any():\n",
        "                df.loc[mask, col] = np.nan\n",
        "                masked_cols.append(col)\n",
        "    return df, masked_cols\n",
        "\n",
        "\n",
        "def drop_sparse(df: pd.DataFrame, thresh: float = 0.95):\n",
        "    if thresh >= 1:\n",
        "        return df, []\n",
        "    df = df.copy()\n",
        "    ratios = df.isna().mean()\n",
        "    to_drop = ratios[ratios > thresh].index.tolist()\n",
        "    df = df.drop(columns=to_drop)\n",
        "    return df, to_drop\n",
        "\n",
        "\n",
        "def clean_dataframe(df: pd.DataFrame, drop_na_thresh: float, outlier_z: float, numeric_like_ratio: float = 0.8):\n",
        "    steps = {}\n",
        "    df1 = normalize_columns(df)\n",
        "    df2 = standardize_missing(df1)\n",
        "    df3, numeric_cols = coerce_numeric(df2, numeric_like_ratio=numeric_like_ratio)\n",
        "    steps['numeric_columns'] = numeric_cols\n",
        "\n",
        "    if outlier_z is not None:\n",
        "        df4, masked = mask_outliers(df3, threshold=outlier_z)\n",
        "        steps['outlier_masked_cols'] = masked\n",
        "    else:\n",
        "        df4 = df3\n",
        "        steps['outlier_masked_cols'] = []\n",
        "\n",
        "    df5, dropped = drop_sparse(df4, drop_na_thresh)\n",
        "    steps['dropped_columns'] = dropped\n",
        "\n",
        "    return df5, steps\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55be388a",
      "metadata": {},
      "source": [
        "## Carga de datos\n",
        "Usamos el dataset limpio generado previamente; si no existe lo creamos aplicando las funciones locales de limpieza.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "5e434bf3",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset shape: (5937, 96)\n",
            "Target column: caravan\n",
            "Positive rate: 0.11051816147357549\n"
          ]
        }
      ],
      "source": [
        "project_root = Path('..').resolve()\n",
        "params = yaml.safe_load((project_root / 'config' / 'params.yaml').read_text())\n",
        "clean_path = (project_root / params['paths']['interim']).resolve()\n",
        "raw_path = (project_root / 'data' / 'enriched' / 'insurance_company_enriched.csv').resolve()\n",
        "clean_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "if not clean_path.exists():\n",
        "    print('Limpieza no encontrada, recreando...')\n",
        "    df_clean, summary = clean_dataframe(\n",
        "        load_raw_dataframe(raw_path),\n",
        "        drop_na_thresh=params['clean']['drop_na_thresh'],\n",
        "        outlier_z=params['clean']['outlier_z'],\n",
        "        numeric_like_ratio=0.8,\n",
        "    )\n",
        "    if clean_path.suffix == '.parquet':\n",
        "        df_clean.to_parquet(clean_path, index=False)\n",
        "    else:\n",
        "        df_clean.to_csv(clean_path, index=False)\n",
        "\n",
        "df = pd.read_parquet(clean_path) if clean_path.suffix == '.parquet' else pd.read_csv(clean_path)\n",
        "\n",
        "target_col = 'caravan' if 'caravan' in df.columns else 'CARAVAN'\n",
        "print('Dataset shape:', df.shape)\n",
        "print('Target column:', target_col)\n",
        "print('Positive rate:', df[target_col].dropna().astype(float).mean())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "62a7ffa3",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(5937, 85) 0.10813542193026782\n"
          ]
        }
      ],
      "source": [
        "target_col = 'caravan'\n",
        "label_cols = [c for c in df.columns if c.endswith('_label')]\n",
        "features = df.drop(columns=label_cols + [target_col], errors='ignore')\n",
        "X = features.apply(pd.to_numeric, errors='coerce').fillna(0.0)\n",
        "y = df[target_col].fillna(0).astype(int)\n",
        "print(X.shape, y.mean())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a2a3874",
      "metadata": {},
      "source": [
        "## Entrenamiento\n",
        "Creamos un pipeline simple (escalado + regresión logística) para obtener un baseline.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "80b3505f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0 1]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.964     0.666     0.788      1117\n",
            "           1      0.103     0.606     0.177        71\n",
            "\n",
            "    accuracy                          0.662      1188\n",
            "   macro avg      0.534     0.636     0.482      1188\n",
            "weighted avg      0.912     0.662     0.751      1188\n",
            "\n",
            "ROC-AUC: 0.6693923613300212\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "# Asegurar tipo numérico\n",
        "y = pd.to_numeric(df[target_col], errors='coerce').fillna(0)\n",
        "\n",
        "# Convertir todos los valores >1 en 1\n",
        "y = np.where(y > 1, 1, y).astype(int)\n",
        "\n",
        "print(np.unique(y))\n",
        "\n",
        "# Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y  # ahora sí puedes estratificar\n",
        ")\n",
        "\n",
        "# Pipeline\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('clf', LogisticRegression(max_iter=500, class_weight='balanced'))\n",
        "])\n",
        "\n",
        "# Entrenamiento\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Predicción\n",
        "y_pred = pipeline.predict(X_test)\n",
        "y_score = pipeline.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Métricas\n",
        "print(classification_report(y_test, y_pred, digits=3))\n",
        "print('ROC-AUC:', roc_auc_score(y_test, y_score))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8de6bf7e",
      "metadata": {},
      "source": [
        "**Interpretación de métricas**\n",
        "\n",
        "- `precision` y `recall` para la clase positiva resumen cómo el modelo acierta sobre los clientes con Caravan; valores desbalanceados adelantan la necesidad de ajustar umbrales o balancear la muestra.\n",
        "- El `f1-score` combina ambos efectos y el promedio ponderado ilustra el desempeño general pese al desbalance.\n",
        "- `ROC-AUC` indica la capacidad de ranking; si se mantiene alrededor de 0.65-0.70 hay señal utilizable, pero es conveniente explorar modelos más expresivos y calibración.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e8238dc",
      "metadata": {},
      "source": [
        "## Interpretación rápida\n",
        "Revisamos los coeficientes del modelo para identificar señales preliminares.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "d0d96587",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "0",
                  "rawType": "float64",
                  "type": "float"
                }
              ],
              "ref": "8e690429-4611-4b94-9d8c-014cfe760efa",
              "rows": [
                [
                  "mzpart",
                  "2.8519973846470643"
                ],
                [
                  "maut2",
                  "1.5204643516745606"
                ],
                [
                  "mink7512",
                  "1.4795730924296362"
                ],
                [
                  "mberboer",
                  "1.3630276316471295"
                ],
                [
                  "mrelge",
                  "1.2822123592658237"
                ],
                [
                  "mkoopkla",
                  "1.248265612462498"
                ],
                [
                  "mzfonds",
                  "1.1782207850577164"
                ],
                [
                  "mberarbo",
                  "1.0712142723426565"
                ],
                [
                  "mgodpr",
                  "1.0413116424300253"
                ],
                [
                  "mhhuur",
                  "0.9795172392679995"
                ],
                [
                  "moshoofd",
                  "0.8875481169594175"
                ],
                [
                  "mgemleef",
                  "0.8873167085737266"
                ],
                [
                  "atractor",
                  "0.7966420373190014"
                ],
                [
                  "mrelsa",
                  "0.7348348049859105"
                ],
                [
                  "mgodrk",
                  "0.7335226679737225"
                ]
              ],
              "shape": {
                "columns": 1,
                "rows": 15
              }
            },
            "text/plain": [
              "mzpart      2.851997\n",
              "maut2       1.520464\n",
              "mink7512    1.479573\n",
              "mberboer    1.363028\n",
              "mrelge      1.282212\n",
              "mkoopkla    1.248266\n",
              "mzfonds     1.178221\n",
              "mberarbo    1.071214\n",
              "mgodpr      1.041312\n",
              "mhhuur      0.979517\n",
              "moshoofd    0.887548\n",
              "mgemleef    0.887317\n",
              "atractor    0.796642\n",
              "mrelsa      0.734835\n",
              "mgodrk      0.733523\n",
              "dtype: float64"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clf = pipeline.named_steps['clf']\n",
        "coefs = pd.Series(clf.coef_[0], index=X.columns)\n",
        "coefs.sort_values(key=np.abs, ascending=False).head(15)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1c15689",
      "metadata": {},
      "source": [
        "**Lectura de coeficientes**\n",
        "\n",
        "- Coeficientes positivos empujan la probabilidad hacia la compra; suelen asociarse a hogares con mayor carga de pólizas o ingresos.\n",
        "- Coeficientes negativos sugieren características que desalientan la compra; úsalos para detectar segmentos poco propensos.\n",
        "- Ordenar por magnitud ayuda a seleccionar variables para nuevas transformaciones o para reducir dimensionalidad en modelos posteriores.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
