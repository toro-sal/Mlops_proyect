{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si no se está usando un ambiente virtual, descomentar y ejecutar las siguientes líneas\n",
    "# !pip install numpy\n",
    "# !pip install pandas\n",
    "# !pip install ucimlrepo\n",
    "#!pip install seaborn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chile\\anaconda3\\envs\\devstack\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargando las librerías\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.api.types import CategoricalDtype\n",
    "ignore_warnings = True\n",
    "import seaborn as sns\n",
    "import json\n",
    "#from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "#import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Config mínima ---\n",
    "DICT_TXT = Path(r\"C:\\Users\\chile\\projects\\proy_insurance\\data\\raw\\dictionary.txt\")\n",
    "CSV_PATH = Path(r\"C:\\Users\\chile\\projects\\proy_insurance\\data\\raw\\insurance_company_modified.csv\")\n",
    "OUT_DIR  = Path(r\"C:\\Users\\chile\\projects\\proy_insurance\\data\\clean_data\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "OUT_CSV    = OUT_DIR / \"coil2000_clean.csv\"\n",
    "OUT_REPORT = OUT_DIR / \"coil2000_dtypes_report.csv\"\n",
    "N_COLS = 86\n",
    "CAT_COLS = {\"MOSTYPE\", \"MOSHOOFD\", \"MKOOPKLA\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5940, 86)\n",
      "MOSTYPE ∈ [1, 41]: filas eliminadas = 75\n",
      "MAANTHUI ∈ [1, 10]: filas eliminadas = 67\n",
      "MGEMOMV ∈ [1, 6]: filas eliminadas = 62\n",
      "MGEMLEEF ∈ [1, 6]: filas eliminadas = 67\n",
      "MOSHOOFD ∈ [1, 10]: filas eliminadas = 56\n",
      "MGODRK ∈ [0, 9]: filas eliminadas = 26\n",
      "PWAPART ∈ [0, 9]: filas eliminadas = 42\n",
      "AWAPART ∈ [1, 12]: filas eliminadas = 2927\n",
      "CARAVAN ∈ [0, 1]: filas eliminadas = 8\n",
      "Filas eliminadas por nulos/vacíos: 1267\n",
      "Guardado dataset limpio: C:\\Users\\chile\\projects\\proy_insurance\\data\\clean_data\\coil2000_clean.csv\n",
      "Guardado reporte dtypes: C:\\Users\\chile\\projects\\proy_insurance\\data\\clean_data\\coil2000_dtypes_report.csv\n"
     ]
    }
   ],
   "source": [
    "RANGES = {\n",
    "    \"MOSTYPE\":  (1, 41),\n",
    "    \"MAANTHUI\": (1, 10),\n",
    "    \"MGEMOMV\":  (1, 6),\n",
    "    \"MGEMLEEF\": (1, 6),\n",
    "    \"MOSHOOFD\": (1, 10),\n",
    "    \"MGODRK\":   (0, 9),\n",
    "    \"PWAPART\":  (0, 9),\n",
    "    \"AWAPART\":  (1, 12),\n",
    "    \"CARAVAN\":  (0, 1),\n",
    "}\n",
    "\n",
    "INVALID_PATTERN = re.compile(r\"(?i)^\\s*$|^(nan|none|null|n/a|invalid|\\?|unknown|error|missing|-)$\")\n",
    "\n",
    "# 1) Diccionario -> nombres (simple)\n",
    "def parse_dictionary(txt_path: Path):\n",
    "    txt = txt_path.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "    names = []\n",
    "    in_table = False\n",
    "    for ln in txt.splitlines():\n",
    "        ln = ln.strip()\n",
    "        if re.match(r\"^1\\s+\\S+\", ln):  # empieza tabla\n",
    "            in_table = True\n",
    "        if not in_table:\n",
    "            continue\n",
    "        if not ln or ln.startswith(\"L0\"):  # termina tabla\n",
    "            break\n",
    "        m = re.match(r\"^(\\d+)\\s+(\\S+)\\s+.*$\", ln)\n",
    "        if m:\n",
    "            names.append((int(m.group(1)), m.group(2)))\n",
    "    cols = [n for _, n in sorted(names, key=lambda x: x[0])]\n",
    "    if len(cols) < N_COLS:\n",
    "        raise ValueError(f\"El diccionario tiene {len(cols)} nombres; se requieren {N_COLS}.\")\n",
    "    return cols[:N_COLS]\n",
    "\n",
    "# 2) Limpieza strings (simple)\n",
    "def normalize_strings_to_nan(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    for c in df.select_dtypes(include=\"object\").columns:\n",
    "        df[c] = df[c].astype(\"string\").str.strip()\n",
    "    return df.replace(INVALID_PATTERN, np.nan, regex=True)\n",
    "\n",
    "# 3) Tipado: 3 categóricas; resto numérico (simple)\n",
    "def cast_types(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    # numérico para no-categóricas\n",
    "    non_cat = [c for c in df.columns if c not in CAT_COLS]\n",
    "    df[non_cat] = df[non_cat].apply(pd.to_numeric, errors=\"coerce\")\n",
    "    # categóricas\n",
    "    for c in CAT_COLS:\n",
    "        if c in df.columns:\n",
    "            df[c] = df[c].astype(\"category\")\n",
    "    return df\n",
    "\n",
    "# 4) Reglas por intervalos cerrados (simple)\n",
    "def apply_interval_rules(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    print(df.shape)\n",
    "\n",
    "    for col, (lo, hi) in RANGES.items():\n",
    "        if col not in df.columns:\n",
    "            continue\n",
    "        # convertir a numérico de forma robusta (string -> numeric)\n",
    "        s = pd.to_numeric(df[col].astype(\"string\").str.strip(), errors=\"coerce\") \\\n",
    "            if col in CAT_COLS or not pd.api.types.is_numeric_dtype(df[col]) else df[col]\n",
    "        mask = s.between(lo, hi, inclusive=\"both\")\n",
    "        removed = (~mask).sum()\n",
    "        if removed:\n",
    "            print(f\"{col} ∈ [{lo}, {hi}]: filas eliminadas = {removed}\")\n",
    "        df = df[mask].copy()\n",
    "    # CARAVAN a int si procede\n",
    "    if \"CARAVAN\" in df.columns:\n",
    "        vals = set(pd.Series(df[\"CARAVAN\"]).dropna().unique().tolist())\n",
    "        if vals <= {0, 1}:\n",
    "            df[\"CARAVAN\"] = pd.to_numeric(df[\"CARAVAN\"], errors=\"coerce\").astype(\"Int64\").astype(\"int64\")\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    return df\n",
    "\n",
    "# 5) Sin nulos en salida (simple)\n",
    "def enforce_no_nulls(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.replace(r\"^\\s*$\", np.nan, regex=True)\n",
    "    before = len(df)\n",
    "    df = df.dropna().reset_index(drop=True)\n",
    "    print(f\"Filas eliminadas por nulos/vacíos: {before - len(df)}\")\n",
    "    return df\n",
    "\n",
    "# 6) Pipeline principal (compacto)\n",
    "def main():\n",
    "    cols = parse_dictionary(DICT_TXT)\n",
    "\n",
    "    df = pd.read_csv(CSV_PATH, header=None)\n",
    "    if df.shape[1] < N_COLS:\n",
    "        raise ValueError(f\"El CSV tiene {df.shape[1]} columnas; se requieren {N_COLS}.\")\n",
    "    df = df.iloc[:, :N_COLS].copy()\n",
    "    df.columns = cols\n",
    "\n",
    "    df = normalize_strings_to_nan(df)\n",
    "    df = apply_interval_rules(df)\n",
    "    df = cast_types(df)\n",
    "    df = enforce_no_nulls(df)\n",
    "    assert df.isna().sum().sum() == 0\n",
    "\n",
    "    df.to_csv(OUT_CSV, index=False)\n",
    "\n",
    "    report = pd.DataFrame({\n",
    "        \"columna\": df.columns,\n",
    "        \"dtype_final\": df.dtypes.astype(str).values,\n",
    "        \"nulos\": df.isna().sum().values,\n",
    "        \"unicos\": df.nunique(dropna=True).values,\n",
    "        \"es_categorica\": [c in CAT_COLS for c in df.columns],\n",
    "    })\n",
    "    report.to_csv(OUT_REPORT, index=False)\n",
    "\n",
    "    print(f\"Guardado dataset limpio: {OUT_CSV}\")\n",
    "    print(f\"Guardado reporte dtypes: {OUT_REPORT}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "devstack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
